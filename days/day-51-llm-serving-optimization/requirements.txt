# Day 51: LLM Serving & Optimization - vLLM, TensorRT, Inference
# Core LLM serving and optimization dependencies

# PyTorch ecosystem
torch>=2.0.0
torchvision>=0.15.0
torchaudio>=2.0.0

# LLM serving frameworks
vllm>=0.2.0
transformers>=4.30.0
accelerate>=0.20.0

# TensorRT and optimization
tensorrt>=8.6.0
tensorrt-llm>=0.5.0
onnx>=1.14.0
onnxruntime>=1.15.0
onnxruntime-gpu>=1.15.0

# Quantization and optimization
bitsandbytes>=0.41.0
auto-gptq>=0.4.0
optimum>=1.12.0

# Serving and deployment
fastapi>=0.100.0
uvicorn>=0.23.0
gunicorn>=21.0.0
ray>=2.5.0
gradio>=3.40.0

# Async and concurrency
asyncio-mqtt>=0.13.0
aiohttp>=3.8.0
websockets>=11.0.0

# Monitoring and metrics
prometheus-client>=0.17.0
psutil>=5.9.0
nvidia-ml-py3>=7.352.0
py3nvml>=0.2.7
GPUtil>=1.4.0

# Load balancing and scaling
kubernetes>=27.0.0
docker>=6.1.0
redis>=4.6.0
celery>=5.3.0

# Data processing and utilities
numpy>=1.24.0
pandas>=2.0.0
scikit-learn>=1.3.0
matplotlib>=3.7.0
seaborn>=0.12.0

# Development and testing
pytest>=7.4.0
pytest-cov>=4.1.0
pytest-asyncio>=0.21.0
black>=23.0.0
flake8>=6.0.0
mypy>=1.5.0

# Configuration and logging
pyyaml>=6.0
python-dotenv>=1.0.0
loguru>=0.7.0
structlog>=23.1.0

# Performance profiling
py-spy>=0.3.14
memory-profiler>=0.61.0
line-profiler>=4.1.0
pyinstrument>=4.5.0

# Cloud and deployment
boto3>=1.28.0
google-cloud-storage>=2.10.0
azure-storage-blob>=12.17.0

# Networking and communication
requests>=2.31.0
httpx>=0.24.0
grpcio>=1.56.0
grpcio-tools>=1.56.0

# Database and caching
sqlalchemy>=2.0.0
alembic>=1.11.0
pymongo>=4.4.0
motor>=3.2.0

# Security and authentication
cryptography>=41.0.0
pyjwt>=2.8.0
passlib>=1.7.4

# Experiment tracking (optional)
mlflow>=2.5.0
wandb>=0.15.0
tensorboard>=2.13.0