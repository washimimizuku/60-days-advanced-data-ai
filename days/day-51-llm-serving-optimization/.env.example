# Day 51: LLM Serving & Optimization - Environment Configuration Template
# Copy this file to .env and customize the values for your environment

# =============================================================================
# MODEL CONFIGURATION
# =============================================================================

# Model settings
MODEL_NAME=microsoft/DialoGPT-medium
MODEL_PATH=./models/
TOKENIZER_PATH=./tokenizers/

# Model serving configuration
MAX_MODEL_LENGTH=4096
TENSOR_PARALLEL_SIZE=1
PIPELINE_PARALLEL_SIZE=1
DTYPE=float16

# =============================================================================
# vLLM CONFIGURATION
# =============================================================================

# Memory management
GPU_MEMORY_UTILIZATION=0.85
SWAP_SPACE_GB=4
CPU_OFFLOAD_GB=0

# PagedAttention settings
BLOCK_SIZE=16
MAX_NUM_SEQS=256
MAX_NUM_BATCHED_TOKENS=8192

# Performance settings
ENFORCE_EAGER=false
DISABLE_LOG_STATS=false
USE_V2_BLOCK_MANAGER=true

# Quantization settings
QUANTIZATION=none  # none, awq, gptq, squeezellm
QUANTIZATION_PARAM_PATH=

# =============================================================================
# TENSORRT CONFIGURATION
# =============================================================================

# TensorRT-LLM settings
TENSORRT_PRECISION=fp16  # fp32, fp16, int8
TENSORRT_MAX_BATCH_SIZE=8
TENSORRT_MAX_INPUT_LEN=2048
TENSORRT_MAX_OUTPUT_LEN=512

# Optimization settings
USE_GPT_ATTENTION_PLUGIN=true
USE_GEMM_PLUGIN=true
USE_LAYERNORM_PLUGIN=true
ENABLE_CONTEXT_FMHA=true
ENABLE_REMOVE_INPUT_PADDING=true

# CUDA settings
USE_CUDA_GRAPHS=true
CUDA_DEVICE=0
CUDA_VISIBLE_DEVICES=0

# =============================================================================
# SERVING CONFIGURATION
# =============================================================================

# Server settings
HOST=0.0.0.0
PORT=8000
WORKERS=1
MAX_CONCURRENT_REQUESTS=1000

# API settings
API_TIMEOUT_SECONDS=300
MAX_REQUEST_SIZE_MB=10
ENABLE_CORS=true
CORS_ORIGINS=*

# Load balancing
LOAD_BALANCER_STRATEGY=least_connections  # round_robin, least_connections, weighted
HEALTH_CHECK_INTERVAL=30
HEALTH_CHECK_TIMEOUT=5

# =============================================================================
# CONTINUOUS BATCHING
# =============================================================================

# Batching settings
ENABLE_CONTINUOUS_BATCHING=true
MAX_BATCH_SIZE=32
MIN_BATCH_SIZE=1
BATCH_TIMEOUT_MS=10

# Request management
REQUEST_QUEUE_SIZE=1000
MAX_WAITING_TIME_MS=30000
PREEMPTION_MODE=swap  # swap, recompute

# =============================================================================
# SPECULATIVE DECODING
# =============================================================================

# Speculative decoding settings
ENABLE_SPECULATIVE_DECODING=false
DRAFT_MODEL_NAME=microsoft/DialoGPT-small
DRAFT_MODEL_PATH=./models/draft/
NUM_SPECULATIVE_TOKENS=4

# Draft model configuration
DRAFT_MODEL_DTYPE=float16
DRAFT_MODEL_MAX_LENGTH=2048
ACCEPTANCE_THRESHOLD=0.6

# =============================================================================
# PERFORMANCE MONITORING
# =============================================================================

# Monitoring settings
ENABLE_MONITORING=true
METRICS_PORT=9090
METRICS_INTERVAL_SECONDS=10

# Performance thresholds
MAX_LATENCY_MS=200
MIN_THROUGHPUT_TPS=50
MAX_ERROR_RATE=0.05
MAX_QUEUE_LENGTH=100

# Alert settings
ENABLE_ALERTS=true
ALERT_EMAIL=admin@example.com
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK

# =============================================================================
# AUTO-SCALING CONFIGURATION
# =============================================================================

# Scaling settings
ENABLE_AUTO_SCALING=true
MIN_INSTANCES=1
MAX_INSTANCES=10
TARGET_UTILIZATION=0.7

# Scale-up triggers
SCALE_UP_CPU_THRESHOLD=80
SCALE_UP_GPU_THRESHOLD=90
SCALE_UP_LATENCY_THRESHOLD_MS=200
SCALE_UP_QUEUE_THRESHOLD=50

# Scale-down triggers
SCALE_DOWN_CPU_THRESHOLD=30
SCALE_DOWN_GPU_THRESHOLD=40
SCALE_DOWN_UTILIZATION_THRESHOLD=0.3

# Scaling policies
SCALE_UP_COOLDOWN_SECONDS=300
SCALE_DOWN_COOLDOWN_SECONDS=600
INSTANCE_WARMUP_TIME_SECONDS=180

# =============================================================================
# COST OPTIMIZATION
# =============================================================================

# Cost settings
INSTANCE_TYPE=a100_40gb  # a100_40gb, a100_80gb, h100_80gb, v100_32gb, t4_16gb
PRICING_MODEL=on_demand  # on_demand, spot, reserved
ENABLE_SPOT_INSTANCES=false

# Budget controls
DAILY_BUDGET_LIMIT=100
MONTHLY_BUDGET_LIMIT=3000
ENABLE_BUDGET_ALERTS=true

# Cost optimization
ENABLE_IDLE_SHUTDOWN=true
IDLE_TIMEOUT_MINUTES=30
SCHEDULED_SCALING=true

# =============================================================================
# LOGGING AND DEBUGGING
# =============================================================================

# Logging configuration
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_FILE=./logs/llm_serving.log
ENABLE_FILE_LOGGING=true
ENABLE_CONSOLE_LOGGING=true
LOG_ROTATION_SIZE_MB=100

# Debug settings
DEBUG_MODE=false
ENABLE_PROFILING=false
PROFILE_OUTPUT_DIR=./profiles/
ENABLE_MEMORY_PROFILING=false

# Verbose output
VERBOSE_SERVING=false
VERBOSE_BATCHING=false
VERBOSE_MONITORING=false

# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================

# Authentication
ENABLE_AUTHENTICATION=false
API_KEY=your_api_key_here
JWT_SECRET=your_jwt_secret_here

# Rate limiting
ENABLE_RATE_LIMITING=true
RATE_LIMIT_REQUESTS_PER_MINUTE=100
RATE_LIMIT_TOKENS_PER_MINUTE=10000

# Security headers
ENABLE_SECURITY_HEADERS=true
ALLOWED_HOSTS=localhost,127.0.0.1

# =============================================================================
# STORAGE CONFIGURATION
# =============================================================================

# Local storage
MODEL_CACHE_DIR=./cache/models/
LOGS_DIR=./logs/
METRICS_DIR=./metrics/

# Cloud storage (optional)
AWS_S3_BUCKET=your-model-bucket
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key

# Google Cloud Storage
GCS_BUCKET=your-model-bucket
GOOGLE_APPLICATION_CREDENTIALS=./credentials/gcs-key.json

# Azure Blob Storage
AZURE_STORAGE_ACCOUNT=your_storage_account
AZURE_STORAGE_KEY=your_storage_key
AZURE_CONTAINER=your-container

# =============================================================================
# KUBERNETES CONFIGURATION
# =============================================================================

# Kubernetes settings (if deploying on K8s)
KUBERNETES_NAMESPACE=llm-serving
KUBERNETES_SERVICE_ACCOUNT=llm-serving-sa
KUBERNETES_CONFIG_PATH=~/.kube/config

# Resource limits
KUBERNETES_CPU_REQUEST=2
KUBERNETES_CPU_LIMIT=8
KUBERNETES_MEMORY_REQUEST=8Gi
KUBERNETES_MEMORY_LIMIT=32Gi
KUBERNETES_GPU_LIMIT=1

# Horizontal Pod Autoscaler
HPA_MIN_REPLICAS=1
HPA_MAX_REPLICAS=10
HPA_TARGET_CPU_UTILIZATION=70
HPA_TARGET_MEMORY_UTILIZATION=80

# =============================================================================
# EXPERIMENT TRACKING
# =============================================================================

# MLflow settings
MLFLOW_TRACKING_URI=http://localhost:5000
MLFLOW_EXPERIMENT_NAME=llm_serving_experiments
ENABLE_MLFLOW_LOGGING=false

# Weights & Biases
WANDB_PROJECT=llm-serving-optimization
WANDB_ENTITY=your_entity
ENABLE_WANDB_LOGGING=false

# TensorBoard
TENSORBOARD_LOG_DIR=./tensorboard_logs/
ENABLE_TENSORBOARD=false

# =============================================================================
# DEVELOPMENT SETTINGS
# =============================================================================

# Development mode
DEVELOPMENT_MODE=true
RELOAD_ON_CHANGE=true
ENABLE_DEBUG_ENDPOINTS=true

# Testing
RUN_TESTS_ON_STARTUP=false
TEST_DATA_PATH=./test_data/
ENABLE_LOAD_TESTING=false

# Mock settings (for development)
USE_MOCK_MODEL=false
MOCK_LATENCY_MS=100
MOCK_THROUGHPUT_TPS=80

# =============================================================================
# INTEGRATION SETTINGS
# =============================================================================

# External services
REDIS_URL=redis://localhost:6379
DATABASE_URL=postgresql://user:pass@localhost/llm_serving
ELASTICSEARCH_URL=http://localhost:9200

# Message queues
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# Distributed tracing
JAEGER_AGENT_HOST=localhost
JAEGER_AGENT_PORT=6831
ENABLE_TRACING=false

# =============================================================================
# CUSTOM CONFIGURATION
# =============================================================================

# Custom model configurations
CUSTOM_MODEL_CONFIG={}
CUSTOM_SERVING_CONFIG={}
CUSTOM_OPTIMIZATION_CONFIG={}

# Feature flags
ENABLE_EXPERIMENTAL_FEATURES=false
ENABLE_BETA_OPTIMIZATIONS=false
ENABLE_RESEARCH_MODE=false

# Environment-specific overrides
ENVIRONMENT=development  # development, staging, production
CONFIG_OVERRIDE_FILE=./config/override.yaml