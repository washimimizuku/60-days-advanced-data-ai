#!/usr/bin/env python3
"""
Interactive Recommendation Systems Demo
Demonstrates all recommendation methods with real data examples
"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.decomposition import TruncatedSVD
from sklearn.metrics import mean_squared_error, mean_absolute_error

# Set style
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

def create_sample_data():
    """Create comprehensive sample recommendation system data"""
    
    print("ðŸ“Š Creating sample recommendation system datasets...")
    
    # Generate users
    np.random.seed(42)
    n_users = 1000
    n_items = 500
    
    # User demographics
    users_df = pd.DataFrame({
        'user_id': range(n_users),
        'age': np.random.normal(35, 12, n_users).astype(int),
        'gender': np.random.choice(['M', 'F'], n_users),
        'location': np.random.choice(['US', 'EU', 'ASIA'], n_users, p=[0.5, 0.3, 0.2])
    })
    users_df['age'] = np.clip(users_df['age'], 18, 80)
    
    # Generate items with features
    categories = ['Action', 'Comedy', 'Drama', 'Horror', 'Romance', 'Sci-Fi', 'Documentary']
    items_df = pd.DataFrame({
        'item_id': range(n_items),
        'category': np.random.choice(categories, n_items),
        'year': np.random.randint(1990, 2024, n_items),
        'duration': np.random.normal(120, 30, n_items).astype(int),
        'avg_rating': np.random.beta(8, 2, n_items) * 4 + 1  # Skewed toward higher ratings
    })
    items_df['duration'] = np.clip(items_df['duration'], 60, 240)
    
    # Generate item descriptions for content-based filtering
    descriptions = []
    for _, item in items_df.iterrows():
        if item['category'] == 'Action':
            desc = f"Thrilling {item['category'].lower()} movie with intense sequences and adventure"
        elif item['category'] == 'Comedy':
            desc = f"Hilarious {item['category'].lower()} film with great humor and entertainment"
        elif item['category'] == 'Drama':
            desc = f"Compelling {item['category'].lower()} story with deep characters and emotion"
        elif item['category'] == 'Horror':
            desc = f"Scary {item['category'].lower()} movie with suspense and frightening scenes"
        elif item['category'] == 'Romance':
            desc = f"Romantic {item['category'].lower()} film with love story and relationships"
        elif item['category'] == 'Sci-Fi':
            desc = f"Futuristic {item['category'].lower()} movie with technology and space adventure"
        else:
            desc = f"Educational {item['category'].lower()} with real-world insights and information"
        descriptions.append(desc)
    
    items_df['description'] = descriptions
    
    # Generate user-item interactions (ratings)
    interactions = []
    
    for user_id in range(n_users):
        # Each user rates 10-50 items
        n_ratings = np.random.randint(10, 51)
        
        # Users have preferences for certain categories
        user_age = users_df.loc[user_id, 'age']
        preferred_categories = []
        
        if user_age < 25:
            preferred_categories = ['Action', 'Horror', 'Sci-Fi']
        elif user_age < 40:
            preferred_categories = ['Action', 'Comedy', 'Romance']
        else:
            preferred_categories = ['Drama', 'Documentary', 'Romance']
        
        # 70% of ratings from preferred categories
        for _ in range(int(n_ratings * 0.7)):\n            category = np.random.choice(preferred_categories)\n            candidate_items = items_df[items_df['category'] == category]\n            \n            if len(candidate_items) > 0:\n                item = candidate_items.sample(1).iloc[0]\n                # Higher ratings for preferred categories\n                rating = np.random.normal(4.2, 0.8)\n                rating = np.clip(rating, 1, 5)\n                \n                interactions.append({\n                    'user_id': user_id,\n                    'item_id': item['item_id'],\n                    'rating': rating,\n                    'timestamp': datetime.now() - timedelta(days=np.random.randint(0, 365))\n                })\n        \n        # 30% random ratings\n        for _ in range(int(n_ratings * 0.3)):\n            item_id = np.random.randint(0, n_items)\n            rating = np.random.normal(3.0, 1.2)\n            rating = np.clip(rating, 1, 5)\n            \n            interactions.append({\n                'user_id': user_id,\n                'item_id': item_id,\n                'rating': rating,\n                'timestamp': datetime.now() - timedelta(days=np.random.randint(0, 365))\n            })\n    \n    interactions_df = pd.DataFrame(interactions)\n    interactions_df = interactions_df.drop_duplicates(['user_id', 'item_id'])\n    \n    return users_df, items_df, interactions_df\n\ndef create_user_item_matrix(interactions_df, n_users, n_items):\n    \"\"\"Create user-item rating matrix\"\"\"\n    \n    user_item_matrix = np.zeros((n_users, n_items))\n    \n    for _, interaction in interactions_df.iterrows():\n        user_id = int(interaction['user_id'])\n        item_id = int(interaction['item_id'])\n        rating = float(interaction['rating'])\n        user_item_matrix[user_id, item_id] = rating\n    \n    return user_item_matrix\n\ndef demo_collaborative_filtering(user_item_matrix, users_df, items_df):\n    \"\"\"Demonstrate collaborative filtering\"\"\"\n    \n    print(f\"\\nðŸ¤ Collaborative Filtering Demo\")\n    print(\"-\" * 50)\n    \n    # User-based collaborative filtering\n    print(\"Testing User-based Collaborative Filtering...\")\n    \n    # Calculate user-user similarity\n    user_similarity = cosine_similarity(user_item_matrix)\n    \n    # Select a test user\n    test_user = 0\n    user_ratings = user_item_matrix[test_user]\n    \n    # Find similar users\n    similarities = user_similarity[test_user]\n    similar_users = np.argsort(similarities)[::-1][1:6]  # Top 5 similar users (excluding self)\n    \n    print(f\"\\nUser {test_user} profile:\")\n    rated_items = np.where(user_ratings > 0)[0]\n    print(f\"  Rated {len(rated_items)} items\")\n    print(f\"  Average rating: {user_ratings[rated_items].mean():.2f}\")\n    \n    print(f\"\\nTop 5 similar users:\")\n    for i, similar_user in enumerate(similar_users):\n        similarity_score = similarities[similar_user]\n        similar_ratings = user_item_matrix[similar_user]\n        similar_rated = np.where(similar_ratings > 0)[0]\n        \n        print(f\"  User {similar_user}: similarity={similarity_score:.3f}, \"\n              f\"rated {len(similar_rated)} items, avg={similar_ratings[similar_rated].mean():.2f}\")\n    \n    # Generate recommendations\n    unrated_items = np.where(user_ratings == 0)[0]\n    recommendations = []\n    \n    for item_id in unrated_items[:20]:  # Check first 20 unrated items\n        # Find users who rated this item\n        item_ratings = user_item_matrix[:, item_id]\n        rated_mask = item_ratings > 0\n        \n        if np.any(rated_mask):\n            # Calculate weighted average\n            user_sims = similarities[rated_mask]\n            ratings = item_ratings[rated_mask]\n            \n            if np.sum(np.abs(user_sims)) > 0:\n                pred_rating = np.sum(user_sims * ratings) / np.sum(np.abs(user_sims))\n                recommendations.append((item_id, pred_rating))\n    \n    # Sort recommendations\n    recommendations.sort(key=lambda x: x[1], reverse=True)\n    \n    print(f\"\\nTop 5 Collaborative Filtering Recommendations for User {test_user}:\")\n    for i, (item_id, pred_rating) in enumerate(recommendations[:5]):\n        item_info = items_df.iloc[item_id]\n        print(f\"  {i+1}. {item_info['category']} ({item_info['year']}) - \"\n              f\"Predicted rating: {pred_rating:.2f}\")\n    \n    return recommendations\n\ndef demo_content_based_filtering(items_df, interactions_df, user_item_matrix):\n    \"\"\"Demonstrate content-based filtering\"\"\"\n    \n    print(f\"\\nðŸ“ Content-based Filtering Demo\")\n    print(\"-\" * 50)\n    \n    # Create item feature matrix using descriptions\n    tfidf = TfidfVectorizer(max_features=100, stop_words='english')\n    item_features = tfidf.fit_transform(items_df['description'])\n    \n    # Calculate item-item similarity\n    item_similarity = cosine_similarity(item_features)\n    \n    # Select a test user\n    test_user = 0\n    user_ratings = user_item_matrix[test_user]\n    \n    # Find items the user liked (rating >= 4)\n    liked_items = np.where(user_ratings >= 4)[0]\n    \n    print(f\"\\nUser {test_user} liked items:\")\n    for item_id in liked_items[:5]:  # Show first 5\n        item_info = items_df.iloc[item_id]\n        rating = user_ratings[item_id]\n        print(f\"  {item_info['category']} ({item_info['year']}) - Rating: {rating:.1f}\")\n    \n    # Generate content-based recommendations\n    item_scores = {}\n    \n    for liked_item in liked_items:\n        # Find similar items\n        similarities = item_similarity[liked_item]\n        user_rating = user_ratings[liked_item]\n        \n        for item_id, similarity in enumerate(similarities):\n            if item_id not in liked_items and user_ratings[item_id] == 0:  # Unrated item\n                if item_id not in item_scores:\n                    item_scores[item_id] = 0\n                item_scores[item_id] += similarity * user_rating\n    \n    # Sort recommendations\n    content_recommendations = sorted(item_scores.items(), key=lambda x: x[1], reverse=True)\n    \n    print(f\"\\nTop 5 Content-based Recommendations for User {test_user}:\")\n    for i, (item_id, score) in enumerate(content_recommendations[:5]):\n        item_info = items_df.iloc[item_id]\n        print(f\"  {i+1}. {item_info['category']} ({item_info['year']}) - \"\n              f\"Content score: {score:.3f}\")\n    \n    return content_recommendations\n\ndef demo_matrix_factorization(user_item_matrix, items_df):\n    \"\"\"Demonstrate matrix factorization\"\"\"\n    \n    print(f\"\\nðŸ”¢ Matrix Factorization Demo\")\n    print(\"-\" * 50)\n    \n    # Replace zeros with global mean for SVD\n    matrix_copy = user_item_matrix.copy()\n    global_mean = matrix_copy[matrix_copy > 0].mean()\n    matrix_copy[matrix_copy == 0] = global_mean\n    \n    # Apply SVD\n    n_components = min(50, min(matrix_copy.shape) - 1)\n    svd = TruncatedSVD(n_components=n_components, random_state=42)\n    user_factors = svd.fit_transform(matrix_copy)\n    item_factors = svd.components_.T\n    \n    print(f\"Matrix factorization completed:\")\n    print(f\"  Original matrix shape: {user_item_matrix.shape}\")\n    print(f\"  Number of factors: {n_components}\")\n    print(f\"  Explained variance ratio: {svd.explained_variance_ratio_.sum():.3f}\")\n    \n    # Generate recommendations for test user\n    test_user = 0\n    user_vector = user_factors[test_user]\n    \n    # Calculate predicted ratings\n    predicted_ratings = np.dot(user_vector, item_factors.T)\n    \n    # Get unrated items\n    user_ratings = user_item_matrix[test_user]\n    unrated_items = np.where(user_ratings == 0)[0]\n    \n    # Sort unrated items by predicted rating\n    unrated_predictions = [(item_id, predicted_ratings[item_id]) for item_id in unrated_items]\n    unrated_predictions.sort(key=lambda x: x[1], reverse=True)\n    \n    print(f\"\\nTop 5 Matrix Factorization Recommendations for User {test_user}:\")\n    for i, (item_id, pred_rating) in enumerate(unrated_predictions[:5]):\n        item_info = items_df.iloc[item_id]\n        print(f\"  {i+1}. {item_info['category']} ({item_info['year']}) - \"\n              f\"Predicted rating: {pred_rating:.2f}\")\n    \n    return unrated_predictions, user_factors, item_factors\n\ndef demo_hybrid_recommendations(collab_recs, content_recs, mf_recs, items_df):\n    \"\"\"Demonstrate hybrid recommendation system\"\"\"\n    \n    print(f\"\\nðŸ”€ Hybrid Recommendation Demo\")\n    print(\"-\" * 50)\n    \n    # Combine recommendations with weights\n    collab_weight = 0.4\n    content_weight = 0.3\n    mf_weight = 0.3\n    \n    # Normalize scores and combine\n    combined_scores = {}\n    \n    # Add collaborative filtering scores\n    if collab_recs:\n        max_collab = max(score for _, score in collab_recs)\n        for item_id, score in collab_recs[:20]:\n            normalized_score = score / max_collab if max_collab > 0 else 0\n            combined_scores[item_id] = combined_scores.get(item_id, 0) + collab_weight * normalized_score\n    \n    # Add content-based scores\n    if content_recs:\n        max_content = max(score for _, score in content_recs)\n        for item_id, score in content_recs[:20]:\n            normalized_score = score / max_content if max_content > 0 else 0\n            combined_scores[item_id] = combined_scores.get(item_id, 0) + content_weight * normalized_score\n    \n    # Add matrix factorization scores\n    if mf_recs:\n        max_mf = max(score for _, score in mf_recs)\n        for item_id, score in mf_recs[:20]:\n            normalized_score = score / max_mf if max_mf > 0 else 0\n            combined_scores[item_id] = combined_scores.get(item_id, 0) + mf_weight * normalized_score\n    \n    # Sort by combined score\n    hybrid_recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n    \n    print(f\"Hybrid recommendation weights:\")\n    print(f\"  Collaborative Filtering: {collab_weight}\")\n    print(f\"  Content-based: {content_weight}\")\n    print(f\"  Matrix Factorization: {mf_weight}\")\n    \n    print(f\"\\nTop 5 Hybrid Recommendations:\")\n    for i, (item_id, score) in enumerate(hybrid_recommendations[:5]):\n        item_info = items_df.iloc[item_id]\n        print(f\"  {i+1}. {item_info['category']} ({item_info['year']}) - \"\n              f\"Hybrid score: {score:.3f}\")\n    \n    return hybrid_recommendations\n\ndef demo_evaluation_metrics(user_item_matrix, recommendations, test_user=0):\n    \"\"\"Demonstrate recommendation evaluation\"\"\"\n    \n    print(f\"\\nðŸ“Š Evaluation Metrics Demo\")\n    print(\"-\" * 50)\n    \n    # Split user ratings into train/test\n    user_ratings = user_item_matrix[test_user]\n    rated_items = np.where(user_ratings > 0)[0]\n    \n    if len(rated_items) < 10:\n        print(\"Not enough ratings for evaluation\")\n        return\n    \n    # Use 80% for training, 20% for testing\n    n_test = max(1, len(rated_items) // 5)\n    test_items = np.random.choice(rated_items, n_test, replace=False)\n    \n    # Get recommended items\n    recommended_items = [item_id for item_id, _ in recommendations[:10]]\n    \n    # Calculate metrics\n    # Precision@K: fraction of recommended items that are relevant\n    relevant_items = test_items[user_ratings[test_items] >= 4]  # Items rated >= 4 are relevant\n    precision_at_10 = len(set(recommended_items) & set(relevant_items)) / len(recommended_items)\n    \n    # Coverage: fraction of items that can be recommended\n    total_items = user_item_matrix.shape[1]\n    coverage = len(set(item_id for item_id, _ in recommendations)) / total_items\n    \n    # Diversity: average pairwise distance between recommended items\n    if len(recommended_items) > 1:\n        categories = [items_df.iloc[item_id]['category'] for item_id in recommended_items]\n        unique_categories = len(set(categories))\n        diversity = unique_categories / len(categories)\n    else:\n        diversity = 0\n    \n    print(f\"Evaluation Results for User {test_user}:\")\n    print(f\"  Test items: {len(test_items)}\")\n    print(f\"  Relevant items (rating >= 4): {len(relevant_items)}\")\n    print(f\"  Precision@10: {precision_at_10:.3f}\")\n    print(f\"  Coverage: {coverage:.3f}\")\n    print(f\"  Category Diversity: {diversity:.3f}\")\n    \n    return {\n        'precision_at_10': precision_at_10,\n        'coverage': coverage,\n        'diversity': diversity\n    }\n\ndef visualize_results(users_df, items_df, interactions_df, user_item_matrix):\n    \"\"\"Create visualizations of recommendation system data and results\"\"\"\n    \n    print(f\"\\nðŸ“ˆ Creating Visualizations...\")\n    \n    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n    \n    # 1. User age distribution\n    axes[0, 0].hist(users_df['age'], bins=20, alpha=0.7, color='skyblue')\n    axes[0, 0].set_title('User Age Distribution')\n    axes[0, 0].set_xlabel('Age')\n    axes[0, 0].set_ylabel('Count')\n    \n    # 2. Item category distribution\n    category_counts = items_df['category'].value_counts()\n    axes[0, 1].bar(category_counts.index, category_counts.values, color='lightcoral')\n    axes[0, 1].set_title('Item Category Distribution')\n    axes[0, 1].set_xlabel('Category')\n    axes[0, 1].set_ylabel('Count')\n    axes[0, 1].tick_params(axis='x', rotation=45)\n    \n    # 3. Rating distribution\n    axes[0, 2].hist(interactions_df['rating'], bins=20, alpha=0.7, color='lightgreen')\n    axes[0, 2].set_title('Rating Distribution')\n    axes[0, 2].set_xlabel('Rating')\n    axes[0, 2].set_ylabel('Count')\n    \n    # 4. User activity (number of ratings per user)\n    user_activity = interactions_df['user_id'].value_counts()\n    axes[1, 0].hist(user_activity.values, bins=20, alpha=0.7, color='orange')\n    axes[1, 0].set_title('User Activity Distribution')\n    axes[1, 0].set_xlabel('Number of Ratings')\n    axes[1, 0].set_ylabel('Number of Users')\n    \n    # 5. Item popularity (number of ratings per item)\n    item_popularity = interactions_df['item_id'].value_counts()\n    axes[1, 1].hist(item_popularity.values, bins=20, alpha=0.7, color='purple')\n    axes[1, 1].set_title('Item Popularity Distribution')\n    axes[1, 1].set_xlabel('Number of Ratings')\n    axes[1, 1].set_ylabel('Number of Items')\n    \n    # 6. Sparsity visualization (sample of user-item matrix)\n    sample_matrix = user_item_matrix[:50, :50]  # Sample 50x50 for visualization\n    im = axes[1, 2].imshow(sample_matrix, cmap='Blues', aspect='auto')\n    axes[1, 2].set_title('User-Item Matrix Sample\\n(Blue = Ratings, White = No Rating)')\n    axes[1, 2].set_xlabel('Items')\n    axes[1, 2].set_ylabel('Users')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Calculate and display sparsity\n    total_possible = user_item_matrix.shape[0] * user_item_matrix.shape[1]\n    actual_ratings = np.count_nonzero(user_item_matrix)\n    sparsity = 1 - (actual_ratings / total_possible)\n    \n    print(f\"\\nDataset Statistics:\")\n    print(f\"  Users: {len(users_df)}\")\n    print(f\"  Items: {len(items_df)}\")\n    print(f\"  Ratings: {len(interactions_df)}\")\n    print(f\"  Sparsity: {sparsity:.1%}\")\n    print(f\"  Average ratings per user: {len(interactions_df) / len(users_df):.1f}\")\n    print(f\"  Average ratings per item: {len(interactions_df) / len(items_df):.1f}\")\n\ndef main():\n    \"\"\"Main demo function\"\"\"\n    \n    print(\"ðŸš€ Recommendation Systems Interactive Demo\")\n    print(\"=\" * 60)\n    \n    # Create sample data\n    users_df, items_df, interactions_df = create_sample_data()\n    \n    # Create user-item matrix\n    n_users = len(users_df)\n    n_items = len(items_df)\n    user_item_matrix = create_user_item_matrix(interactions_df, n_users, n_items)\n    \n    print(f\"\\nðŸ“Š Dataset Overview:\")\n    print(f\"  Users: {n_users}\")\n    print(f\"  Items: {n_items}\")\n    print(f\"  Interactions: {len(interactions_df)}\")\n    \n    # Demo different recommendation approaches\n    collab_recs = demo_collaborative_filtering(user_item_matrix, users_df, items_df)\n    content_recs = demo_content_based_filtering(items_df, interactions_df, user_item_matrix)\n    mf_recs, user_factors, item_factors = demo_matrix_factorization(user_item_matrix, items_df)\n    \n    # Demo hybrid approach\n    hybrid_recs = demo_hybrid_recommendations(collab_recs, content_recs, mf_recs, items_df)\n    \n    # Demo evaluation\n    metrics = demo_evaluation_metrics(user_item_matrix, hybrid_recs)\n    \n    # Create visualizations\n    visualize_results(users_df, items_df, interactions_df, user_item_matrix)\n    \n    print(\"\\nðŸŽ¯ Demo Summary:\")\n    print(\"âœ… Collaborative Filtering: Leverages user behavior patterns\")\n    print(\"âœ… Content-based Filtering: Uses item features and descriptions\")\n    print(\"âœ… Matrix Factorization: Discovers latent factors in user-item interactions\")\n    print(\"âœ… Hybrid Approach: Combines multiple methods for better performance\")\n    print(\"âœ… Evaluation Metrics: Measures recommendation quality and diversity\")\n    \n    print(\"\\nðŸ’¡ Key Insights:\")\n    print(\"â€¢ Collaborative filtering works well with sufficient user interaction data\")\n    print(\"â€¢ Content-based filtering handles new items and provides explainability\")\n    print(\"â€¢ Matrix factorization scales well and captures latent preferences\")\n    print(\"â€¢ Hybrid approaches balance different recommendation strengths\")\n    print(\"â€¢ Evaluation should consider accuracy, diversity, and coverage\")\n    \n    print(\"\\nðŸš€ Ready for production recommendation systems!\")\n\nif __name__ == \"__main__\":\n    main()