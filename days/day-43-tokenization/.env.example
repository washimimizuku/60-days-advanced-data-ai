# Day 43: Tokenization Strategies - Environment Configuration

# Tokenizer Configuration
DEFAULT_VOCAB_SIZE=30000
DEFAULT_MIN_FREQUENCY=2
MAX_TOKEN_LENGTH=50

# Text Normalization
NORMALIZATION_FORM=nfc  # nfc, nfd, nfkc, nfkd
HANDLE_CONTRACTIONS=true
LOWERCASE_TEXT=false
REMOVE_ACCENTS=false

# Performance Settings
CACHE_SIZE=10000
BATCH_SIZE=32
NUM_WORKERS=4

# Training Configuration
BPE_MERGES=25000
WORDPIECE_LIKELIHOOD_THRESHOLD=0.01
SENTENCEPIECE_COVERAGE=0.9995

# Multilingual Settings
DETECT_SCRIPTS=true
SCRIPT_SPECIFIC_NORMALIZATION=true
UNIFIED_VOCABULARY=true

# Evaluation Settings
BENCHMARK_RUNS=3
COMPRESSION_RATIO_TARGET=4.0
MAX_UNK_RATE=0.05

# Development Settings
DEBUG_MODE=false
VERBOSE_LOGGING=true
SAVE_INTERMEDIATE_MODELS=false
SEED=42

# Output Configuration
MODEL_SAVE_PATH=./models
RESULTS_SAVE_PATH=./results
PLOT_SAVE_PATH=./plots