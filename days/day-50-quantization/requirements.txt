# Day 50: Quantization - Model Compression & Optimization
# Core quantization and optimization dependencies

# PyTorch ecosystem
torch>=2.0.0
torchvision>=0.15.0
torchaudio>=2.0.0

# Quantization libraries
transformers>=4.30.0
accelerate>=0.20.0
bitsandbytes>=0.41.0
auto-gptq>=0.4.0
optimum>=1.12.0

# GGUF and llama.cpp integration
llama-cpp-python>=0.2.0
gguf>=0.1.0

# Hardware optimization
intel-extension-for-pytorch>=2.0.0  # Intel optimizations
onnx>=1.14.0
onnxruntime>=1.15.0
tensorrt>=8.6.0  # NVIDIA TensorRT (if available)

# Monitoring and metrics
psutil>=5.9.0
nvidia-ml-py3>=7.352.0
py3nvml>=0.2.7

# Data processing and utilities
numpy>=1.24.0
pandas>=2.0.0
scikit-learn>=1.3.0
matplotlib>=3.7.0
seaborn>=0.12.0

# Development and testing
pytest>=7.4.0
pytest-cov>=4.1.0
black>=23.0.0
flake8>=6.0.0
mypy>=1.5.0

# Jupyter and visualization
jupyter>=1.0.0
ipywidgets>=8.0.0
plotly>=5.15.0

# Configuration and logging
pyyaml>=6.0
python-dotenv>=1.0.0
loguru>=0.7.0

# Performance profiling
py-spy>=0.3.14
memory-profiler>=0.61.0
line-profiler>=4.1.0

# Model serving (optional)
fastapi>=0.100.0
uvicorn>=0.23.0
gradio>=3.40.0

# Cloud and deployment (optional)
boto3>=1.28.0
google-cloud-storage>=2.10.0
azure-storage-blob>=12.17.0