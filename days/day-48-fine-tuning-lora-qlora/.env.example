# Day 48: Fine-tuning Techniques - LoRA & QLoRA - Environment Configuration

# =============================================================================
# Model Configuration
# =============================================================================

# Base model settings
BASE_MODEL_NAME="microsoft/DialoGPT-medium"
MODEL_CACHE_DIR="./models"
MAX_MODEL_SIZE_GB=50

# LoRA Configuration
LORA_RANK=16
LORA_ALPHA=32
LORA_DROPOUT=0.1
LORA_TARGET_MODULES="q_proj,v_proj"

# QLoRA Configuration
ENABLE_QLORA=true
QUANTIZATION_TYPE="nf4"
COMPUTE_DTYPE="bfloat16"
DOUBLE_QUANTIZATION=true

# =============================================================================
# Training Configuration
# =============================================================================

# Training hyperparameters
LEARNING_RATE=5e-4
BATCH_SIZE=16
GRADIENT_ACCUMULATION_STEPS=4
MAX_EPOCHS=3
WARMUP_RATIO=0.1
WEIGHT_DECAY=0.01

# Optimization settings
ENABLE_GRADIENT_CHECKPOINTING=true
ENABLE_MIXED_PRECISION=true
MAX_GRAD_NORM=1.0

# Scheduler settings
SCHEDULER_TYPE="cosine"
COSINE_RESTARTS=false

# =============================================================================
# Memory and Performance
# =============================================================================

# Memory management
MAX_MEMORY_GB=24
ENABLE_CPU_OFFLOAD=false
ENABLE_OPTIMIZER_OFFLOAD=false

# Performance settings
NUM_WORKERS=4
PIN_MEMORY=true
PREFETCH_FACTOR=2

# Sequence settings
MAX_SEQUENCE_LENGTH=512
PADDING_SIDE="right"
TRUNCATION_SIDE="right"

# =============================================================================
# Data Configuration
# =============================================================================

# Dataset settings
DATASET_NAME="custom"
DATASET_PATH="./data"
TRAIN_SPLIT=0.8
VALIDATION_SPLIT=0.1
TEST_SPLIT=0.1

# Data preprocessing
TOKENIZER_CACHE_DIR="./tokenizers"
PREPROCESSING_NUM_WORKERS=4
REMOVE_UNUSED_COLUMNS=true

# =============================================================================
# Logging and Monitoring
# =============================================================================

# Weights & Biases
WANDB_PROJECT="lora-fine-tuning"
WANDB_ENTITY=""
WANDB_API_KEY=""
ENABLE_WANDB=false

# TensorBoard
TENSORBOARD_LOG_DIR="./logs/tensorboard"
ENABLE_TENSORBOARD=true

# Logging settings
LOG_LEVEL="INFO"
LOG_FILE="./logs/training.log"
LOG_INTERVAL=10

# Evaluation settings
EVAL_STRATEGY="steps"
EVAL_STEPS=500
SAVE_STRATEGY="steps"
SAVE_STEPS=1000
SAVE_TOTAL_LIMIT=3

# =============================================================================
# Hardware Configuration
# =============================================================================

# CUDA settings
CUDA_VISIBLE_DEVICES="0"
TORCH_CUDA_ARCH_LIST="7.5,8.0,8.6"

# CPU settings
OMP_NUM_THREADS=8
MKL_NUM_THREADS=8

# Memory settings
PYTORCH_CUDA_ALLOC_CONF="max_split_size_mb:128"

# =============================================================================
# Multi-Task Configuration
# =============================================================================

# Task management
ENABLE_MULTITASK=false
TASK_NAMES="task1,task2,task3"
TASK_WEIGHTS="0.4,0.4,0.2"

# Adapter management
ADAPTER_SAVE_DIR="./adapters"
ENABLE_ADAPTER_MERGING=false
MERGE_WEIGHTS="0.5,0.5"

# =============================================================================
# Deployment Configuration
# =============================================================================

# Model serving
SERVE_MODEL=false
SERVE_HOST="0.0.0.0"
SERVE_PORT=8000
MAX_CONCURRENT_REQUESTS=10

# API settings
API_KEY=""
RATE_LIMIT_PER_MINUTE=60
ENABLE_CORS=true

# =============================================================================
# Evaluation and Testing
# =============================================================================

# Evaluation metrics
EVAL_METRICS="bleu,rouge,perplexity"
EVAL_BATCH_SIZE=32
EVAL_MAX_LENGTH=128

# Testing settings
TEST_BATCH_SIZE=16
GENERATE_SAMPLES=true
NUM_SAMPLES=100

# Benchmark settings
BENCHMARK_INFERENCE=false
BENCHMARK_ITERATIONS=100
BENCHMARK_WARMUP=10

# =============================================================================
# Security and Privacy
# =============================================================================

# Data privacy
ENABLE_DIFFERENTIAL_PRIVACY=false
DP_NOISE_MULTIPLIER=1.0
DP_MAX_GRAD_NORM=1.0

# Model security
ENABLE_MODEL_ENCRYPTION=false
ENCRYPTION_KEY=""

# =============================================================================
# Development and Debugging
# =============================================================================

# Debug settings
DEBUG_MODE=false
VERBOSE_LOGGING=false
PROFILE_MEMORY=false
PROFILE_PERFORMANCE=false

# Testing settings
RUN_TESTS=false
TEST_COVERAGE=false

# Development settings
AUTO_RELOAD=false
DEVELOPMENT_MODE=false

# =============================================================================
# Advanced Configuration
# =============================================================================

# Experimental features
ENABLE_FLASH_ATTENTION=false
ENABLE_TORCH_COMPILE=false
ENABLE_DEEPSPEED=false

# DeepSpeed configuration
DEEPSPEED_CONFIG_PATH="./configs/deepspeed.json"
DEEPSPEED_STAGE=2

# Advanced optimization
ENABLE_GRADIENT_COMPRESSION=false
COMPRESSION_RATIO=0.1

# Custom configuration
CUSTOM_CONFIG_PATH=""
OVERRIDE_CONFIG=false